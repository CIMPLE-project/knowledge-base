{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Literal, URIRef, XSD\n",
    "from rdflib.namespace import RDF, FOAF, SDO, Namespace\n",
    "import json\n",
    "import io\n",
    "from tqdm import tqdm, trange\n",
    "import re\n",
    "import requests\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76398601",
   "metadata": {},
   "outputs": [],
   "source": [
    "SO = Namespace(\"http://schema.org/\")\n",
    "WIKI_prefix = \"http://www.wikidata.org/wiki/\"\n",
    "DB_prefix = \"http://dbpedia.org/ontology/\"\n",
    "\n",
    "prefix = \"http://claimreview-kb.tools.eurecom.fr/\"\n",
    "\n",
    "g = Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00387642",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../../ClaimReviews2023/'\n",
    "\n",
    "claim_reviews = json.load(io.open(directory+'2023_05_02/claim_reviews.json'))\n",
    "\n",
    "#claim_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a38067",
   "metadata": {},
   "source": [
    "# Extract Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0cf7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.replace('&amp;', '&')\n",
    "    text = text.replace('\\xa0', '')\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6af4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEXT = [cr['claim_text'][0] for cr in claim_reviews]\n",
    "API_URL = \"https://api.dbpedia-spotlight.org/en/annotate\"\n",
    "\n",
    "\n",
    "entities_dbpedia = []\n",
    "for s in tqdm(TEXT):\n",
    "    s = normalize_text(s)\n",
    "    if not s in ['', ' ', '   ']:\n",
    "        payload = {'text': s}\n",
    "        a = requests.post(API_URL, \n",
    "                     headers={'accept': 'application/json'},\n",
    "                     data=payload).json()\n",
    "\n",
    "        entities_dbpedia.append(a)\n",
    "    else:\n",
    "        entities_dbpedia.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(directory+'entities.json', 'w') as f:\n",
    "    json.dump(entities_dbpedia, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dabe6b",
   "metadata": {},
   "source": [
    "# Populate graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uri_generator(identifier):\n",
    "    h = hashlib.sha224(str.encode(identifier)).hexdigest()\n",
    "    \n",
    "    return str(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(directory+'entities.json', 'r') as f:\n",
    "    entities_dbpedia = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aee017",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(0, len(claim_reviews)):\n",
    "    cr = claim_reviews[i]\n",
    "    \n",
    "    identifier = 'claim_reviews'+str(i)\n",
    "    uri = 'claim_reviews/'+uri_generator(identifier)\n",
    "    g.add((URIRef(prefix+uri), RDF.type, SO.ClaimReview))\n",
    "    \n",
    "    author = cr['fact_checker']['name']\n",
    "    website = cr['fact_checker']['website']\n",
    "    identifier_author = 'organization'+str(author)\n",
    "    uri_author = 'organization/'+uri_generator(identifier_author)\n",
    "    \n",
    "    g.add((URIRef(prefix+uri_author), RDF.type, SO.Organization))\n",
    "    g.add((URIRef(prefix+uri_author), SO.name, Literal(author)))\n",
    "    g.add((URIRef(prefix+uri_author), SO.url, URIRef(website)))\n",
    "\n",
    "    g.add((URIRef(prefix+uri), SO.author, URIRef(prefix+uri_author)))\n",
    "    \n",
    "\n",
    "    \n",
    "    date = cr['reviews'][0]['date_published']\n",
    "\n",
    "    g.add((URIRef(prefix+uri), SO.datePublished, Literal(date, datatype=XSD.date)))\n",
    "    \n",
    "    url = cr['review_url']\n",
    "    url = url.replace(' ', '')\n",
    "    g.add((URIRef(prefix+uri), SO.url, URIRef(url)))\n",
    "    \n",
    "    language = cr['fact_checker']['language']\n",
    "    g.add((URIRef(prefix+uri), SO.inLanguage, Literal(language)))\n",
    "    \n",
    "    uri_rating = 'rating/'+cr['reviews'][0]['label']\n",
    "    \n",
    "    g.add((URIRef(prefix+uri), SO.reviewRating, URIRef(prefix+uri_rating)))\n",
    "\n",
    "    \n",
    "    claim = cr['claim_text'][0]\n",
    "    identifier_claim = 'claims'+str(i)\n",
    "    uri_claim = 'claims/'+uri_generator(identifier_claim)\n",
    "    \n",
    "    g.add((URIRef(prefix+uri_claim),RDF.type, SO.Claim))\n",
    "    \n",
    "    g.add((URIRef(prefix+uri), SO.itemReviewed, URIRef(prefix+uri_claim)))\n",
    "\n",
    "    text = claim\n",
    "    text = normalize_text(text)\n",
    "\n",
    "    g.add((URIRef(prefix+uri_claim),SO.text, Literal(text)))\n",
    "    \n",
    "    dbpedia_output = entities_dbpedia[i]\n",
    "    \n",
    "    if 'Resources' in dbpedia_output:\n",
    "        entities = dbpedia_output['Resources']\n",
    "    \n",
    "        for e in entities:\n",
    "            dbpedia_url = e['@URI']\n",
    "            dbpedia_name = e['@URI'][28:].replace('_', ' ')\n",
    "            entity_types = e['@types'].split(',')\n",
    "\n",
    "            identifier_mention = 'entity'+str(dbpedia_url)\n",
    "            uri_mention = 'entity/'+uri_generator(identifier_mention)\n",
    "            \n",
    "            g.add((URIRef(prefix+uri_mention), RDF.type, SO.Thing))\n",
    "            for t in entity_types:\n",
    "                if \"Wikidata\" in t:\n",
    "                    g.add((URIRef(prefix+uri_mention), RDF.type, URIRef(WIKI_prefix+t.split(':')[1])))\n",
    "                if \"DBpedia\" in t:\n",
    "                    g.add((URIRef(prefix+uri_mention), RDF.type, URIRef(DB_prefix+t.split(':')[1])))\n",
    "                    \n",
    "            g.add((URIRef(prefix+uri_mention), SO.url, URIRef(dbpedia_url)))\n",
    "            g.add((URIRef(prefix+uri_mention), SO.name, Literal(dbpedia_name)))\n",
    "            g.add((URIRef(prefix+uri_claim), SO.mentions, URIRef(prefix+uri_mention)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9caa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations_names = []\n",
    "all_organizations_websites = []\n",
    "\n",
    "for cr in claim_reviews:\n",
    "    author = cr['fact_checker']['name']\n",
    "    website = cr['fact_checker']['website']\n",
    "    if author not in all_organizations_names:\n",
    "        all_organizations_names.append(author)\n",
    "        all_organizations_websites.append(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a6619",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_mapping = json.load(io.open(directory+'2023_05_02/claim_labels_mapping.json'))\n",
    "\n",
    "for label in tqdm(labels_mapping):\n",
    "    identifier_original_rating = 'original_rating'+label['original_label']\n",
    "    uri_original_rating = 'original_rating/'+uri_generator(identifier_original_rating)\n",
    "    \n",
    "    g.add((URIRef(prefix+uri_original_rating), RDF.type, SO.Rating))\n",
    "    g.add((URIRef(prefix+uri_original_rating), SO.ratingValue, Literal(label['original_label'])))\n",
    "    g.add((URIRef(prefix+uri_original_rating), SO.name, Literal(label['original_label'].replace('_', ' '))))\n",
    "    \n",
    "    uri_rating = 'rating/'+label['coinform_label']\n",
    "    \n",
    "    g.add((URIRef(prefix+uri_rating), RDF.type, SO.Rating))\n",
    "    g.add((URIRef(prefix+uri_rating), SO.ratingValue, Literal(label['coinform_label'])))\n",
    "    g.add((URIRef(prefix+uri_rating), SO.name, Literal(label['coinform_label'].replace('_', ' '))))\n",
    "    \n",
    "    \n",
    "    g.add((URIRef(prefix+uri_original_rating), SO.sameAs, URIRef(prefix+uri_rating)))\n",
    "\n",
    "    domains = label['domains'].split(',')\n",
    "    for d in label['domains'].split(','):\n",
    "        corresponding_org_website = \"\"\n",
    "        for websites in all_organizations_websites:\n",
    "            if d in websites:\n",
    "                corresponding_org_website=websites\n",
    "        corresponding_org_name = all_organizations_names[all_organizations_websites.index(corresponding_org_website)]\n",
    "        identifier_author = 'organization'+str(corresponding_org_name)\n",
    "        uri_author = 'organization/'+uri_generator(identifier_author)\n",
    "        g.add((URIRef(prefix+uri_original_rating), SO.author, URIRef(prefix+uri_author)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab98010",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f635f3d",
   "metadata": {},
   "source": [
    "# Serialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b0ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.serialize(destination=directory+\"/claimreview-kg.ttl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
